```markdown
# Python Student Competence Analysis: Open Source Model Evaluation

## Project Overview

This research project evaluates open source AI models for generating meaningful prompts that assess student competence in Python programming. The focus is on identifying models capable of analyzing student code, detecting conceptual misconceptions, and generating pedagogically sound prompts that encourage deeper learning.

## Quick Start

```bash
# Clone the repository
git clone https://github.com/lavanyakarna/python-competence-analysis.git
cd python-competence-analysis

# Install dependencies
pip install -r requirements.txt

# Run the evaluation framework
python evaluation-framework.py
```

## Research Objectives

- Evaluate open source models for code analysis and prompt generation
- Focus on Python learning as the test case
- Assess models' ability to detect misconceptions and generate educational prompts
- Provide practical recommendations for educational deployment

## Key Files

- `research-plan.md` - Detailed research methodology and approach
- `evaluation-framework.py` - Implementation of the evaluation system
- `requirements.txt` - Python dependencies
- `setup.py` - Package installation configuration

## Model Focus: CodeT5+

This research primarily evaluates **CodeT5+** due to its:
- Strong performance in code-to-text tasks
- Open source availability
- Reasonable computational requirements
- Active community support

## Expected Outcomes

1. Comprehensive model evaluation report
2. Open source tool for competence analysis  
3. Best practices for educational AI implementation
4. Performance benchmarks and comparisons

## Contact

For questions or collaboration:
- Email: pythonsupport@fossee.in
- GitHub Issues: Use this repository's issues page

## License

MIT License - See LICENSE file for details
```
